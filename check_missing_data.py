#!/usr/bin/env python3
"""
æ£€æŸ¥æ•°æ®ç¼ºå¤±é—®é¢˜çš„è„šæœ¬
"""

import json
import os
import pandas as pd
from collections import defaultdict, Counter

def load_json_files():
    """åŠ è½½æ‰€æœ‰JSONæ–‡ä»¶"""
    data_dir = "json_data/raw_json_files"
    all_data = []

    for file_name in sorted(os.listdir(data_dir)):
        if file_name.endswith('.json'):
            file_path = os.path.join(data_dir, file_name)
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                all_data.append(data)

    return all_data

def analyze_hwkey_distribution():
    """åˆ†æhwKeyåˆ†å¸ƒæƒ…å†µ"""
    all_data = load_json_files()

    model_hwkey_counts = defaultdict(Counter)
    total_counts = Counter()

    for item in all_data:
        if 'data' in item and 'metadata' in item:
            model = item['metadata']['model']
            for record in item['data']:
                hwkey = record.get('hwKey', 'unknown')
                model_hwkey_counts[model][hwkey] += 1
                total_counts[hwkey] += 1

    print("ğŸ” åˆ†æhwKeyåˆ†å¸ƒæƒ…å†µ:\n")

    for model, hwkey_counter in model_hwkey_counts.items():
        print(f"ğŸ“Š {model}:")
        for hwkey, count in sorted(hwkey_counter.items()):
            print(f"  {hwkey}: {count}")
        print()

    print("ğŸ“ˆ æ€»ä½“hwKeyåˆ†å¸ƒ:")
    for hwkey, count in sorted(total_counts.items()):
        print(f"  {hwkey}: {count}")

    return model_hwkey_counts

def check_b200_trt_missing():
    """ä¸“é—¨æ£€æŸ¥b200_trtç¼ºå¤±æƒ…å†µ"""
    all_data = load_json_files()

    print("\nğŸ¯ æ£€æŸ¥b200_trtæ•°æ®ç¼ºå¤±æƒ…å†µ:\n")

    # æ£€æŸ¥æ¯ä¸ªæ¨¡å‹æ˜¯å¦æœ‰b200_trtæ•°æ®
    model_b200_trt_counts = defaultdict(int)
    model_total_records = defaultdict(int)

    for item in all_data:
        if 'data' in item and 'metadata' in item:
            model = item['metadata']['model']
            for record in item['data']:
                model_total_records[model] += 1
                hwkey = record.get('hwKey', '')
                if 'b200' in hwkey.lower() or 'trt' in hwkey.lower():
                    model_b200_trt_counts[model] += 1

    print("ğŸ” å„æ¨¡å‹b200_trtç›¸å…³æ•°æ®ç»Ÿè®¡:")
    for model in sorted(model_total_records.keys()):
        total = model_total_records[model]
        b200_count = model_b200_trt_counts[model]
        print(f"  {model}: æ€»è®°å½•={total}, b200_trtç›¸å…³={b200_count}")

    # æ£€æŸ¥å“ªäº›æ¨¡å‹ç¼ºå°‘b200_trt
    print("\nâŒ ç¼ºå°‘b200_trtæ•°æ®çš„æ¨¡å‹:")
    for model in sorted(model_total_records.keys()):
        if model_b200_trt_counts[model] == 0:
            print(f"  âŒ {model}: å®Œå…¨æ²¡æœ‰b200_trtç›¸å…³æ•°æ®")
        elif model_b200_trt_counts[model] < 20:
            print(f"  âš ï¸  {model}: åªæœ‰{model_b200_trt_counts[model]}æ¡b200_trtç›¸å…³æ•°æ®ï¼Œå¯èƒ½ä¸å®Œæ•´")

    return model_b200_trt_counts

def check_inference_max_website():
    """æ£€æŸ¥InferenceMAXç½‘ç«™ä¸Šgpt-oss 120Bæ¨¡å‹æ˜¯å¦æœ‰b200_trtæ•°æ®"""
    print("\nğŸŒ å»ºè®®æ‰‹åŠ¨æ£€æŸ¥InferenceMAXç½‘ç«™:")
    print("1. è®¿é—® https://inferencemax.semianalysis.com/")
    print("2. é€‰æ‹© 'gpt-oss 120B' æ¨¡å‹")
    print("3. æŸ¥çœ‹ç¡¬ä»¶é€‰é¡¹ä¸­æ˜¯å¦æœ‰ 'b200_trt' é€‰é¡¹")
    print("4. å¦‚æœæœ‰è¯¥é€‰é¡¹ï¼Œè¯´æ˜ç½‘ç«™æœ‰æ•°æ®ä½†çˆ¬å–è„šæœ¬æœ‰é—®é¢˜")
    print("5. å¦‚æœæ²¡æœ‰è¯¥é€‰é¡¹ï¼Œè¯´æ˜ç½‘ç«™æœ¬èº«å°±æ²¡æœ‰è¿™ä¸ªæ•°æ®ç»„åˆ")

def check_json_file_structure():
    """æ£€æŸ¥JSONæ–‡ä»¶ç»“æ„ï¼Œå¯èƒ½çš„æ•°æ®æºé—®é¢˜"""
    print("\nğŸ“‹ æ£€æŸ¥JSONæ–‡ä»¶ç»“æ„:")

    data_dir = "json_data/raw_json_files"

    # æ£€æŸ¥gpt-oss 120Bç›¸å…³æ–‡ä»¶
    gpt_files = [f for f in os.listdir(data_dir) if 'gpt-oss' in f]

    for file_name in sorted(gpt_files):
        file_path = os.path.join(data_dir, file_name)

        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if 'metadata' in data:
            model = data['metadata']['model']
            sequence = data['metadata']['sequence']
            response_type = 'interactivity' if 'interactivity' in data['metadata']['url'] else 'e2e'

            print(f"\nğŸ“„ {file_name}:")
            print(f"  æ¨¡å‹: {model}")
            print(f"  åºåˆ—: {sequence}")
            print(f"  ç±»å‹: {response_type}")
            print(f"  URL: {data['metadata']['url']}")
            print(f"  æ•°æ®æ¡æ•°: {len(data['data'])}")

            # æ£€æŸ¥hwKeyç±»å‹
            hwkeys = set()
            for record in data['data']:
                hwkeys.add(record.get('hwKey', 'unknown'))

            print(f"  hwKeyç±»å‹: {sorted(hwkeys)}")

def main():
    print("ğŸš€ å¼€å§‹æ£€æŸ¥æ•°æ®ç¼ºå¤±é—®é¢˜...")

    # åˆ†æhwKeyåˆ†å¸ƒ
    hwkey_distribution = analyze_hwkey_distribution()

    # æ£€æŸ¥b200_trtç¼ºå¤±æƒ…å†µ
    b200_trt_counts = check_b200_trt_missing()

    # æ£€æŸ¥æ–‡ä»¶ç»“æ„
    check_json_file_structure()

    # å»ºè®®ä¸‹ä¸€æ­¥è¡ŒåŠ¨
    check_inference_max_website()

    print("\nğŸ¯ ç»“è®ºå’Œå»ºè®®:")
    print("1. å¦‚æœç½‘ç«™æœ‰b200_trté€‰é¡¹ä½†æœªçˆ¬å–åˆ°ï¼Œè¯´æ˜çˆ¬å–è„šæœ¬éœ€è¦ä¿®å¤")
    print("2. å¦‚æœç½‘ç«™æœ¬èº«æ²¡æœ‰b200_trté€‰é¡¹ï¼Œè¯´æ˜è¯¥æ•°æ®ç»„åˆä¸å­˜åœ¨")
    print("3. å»ºè®®æ‰‹åŠ¨è®¿é—®ç½‘ç«™ç¡®è®¤gpt-oss 120Bæ¨¡å‹çš„ç¡¬ä»¶é€‰é¡¹")

if __name__ == "__main__":
    main()