#!/usr/bin/env python3
"""
éªŒè¯ç‰ˆæœ¬æ•°æ®çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§
è¯¦ç»†æ£€æŸ¥æ¯ä¸ªç‰ˆæœ¬çš„æ•°æ®ç»“æ„å’Œå†…å®¹
"""

import os
import pandas as pd
import json
import zipfile
import shutil
from datetime import datetime
import tempfile

class VersionDataVerifier:
    def __init__(self, archive_path="inference_max_pipeline/data_archive"):
        self.archive_path = archive_path
        self.versions = []

    def discover_versions(self):
        """å‘ç°æ‰€æœ‰å¯ç”¨çš„ç‰ˆæœ¬"""
        version_dirs = [d for d in os.listdir(self.archive_path)
                      if d.startswith('version_') and os.path.isdir(os.path.join(self.archive_path, d))]
        self.versions = sorted(version_dirs)
        print(f"å‘ç° {len(self.versions)} ä¸ªç‰ˆæœ¬:")
        for i, version in enumerate(self.versions):
            print(f"  {i+1}. {version}")

    def extract_zip_file(self, zip_path, extract_to=None):
        """è§£å‹zipæ–‡ä»¶å¹¶è¿”å›CSVæ–‡ä»¶è·¯å¾„"""
        if extract_to is None:
            extract_to = tempfile.mkdtemp()

        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_to)

        # æŸ¥æ‰¾è§£å‹åçš„CSVæ–‡ä»¶
        csv_files = [f for f in os.listdir(extract_to) if f.endswith('.csv')]
        if csv_files:
            return os.path.join(extract_to, csv_files[0])
        return None

    def load_version_data(self, version):
        """åŠ è½½æŒ‡å®šç‰ˆæœ¬çš„æ•°æ®"""
        version_path = os.path.join(self.archive_path, version)
        data = {}

        try:
            # åŠ è½½metadata
            with open(os.path.join(version_path, 'metadata.json'), 'r') as f:
                data['metadata'] = json.load(f)

            # ä¸´æ—¶ç›®å½•ç”¨äºè§£å‹
            temp_dir_base = f"/tmp/{version}_extract"

            # åŠ è½½e2eæ•°æ®
            e2e_zip = os.path.join(version_path, 'inference_max_e2e.zip.zip')
            if os.path.exists(e2e_zip):
                temp_dir = temp_dir_base + "_e2e"
                e2e_file = self.extract_zip_file(e2e_zip, temp_dir)
                if e2e_file:
                    data['e2e'] = pd.read_csv(e2e_file)

            # åŠ è½½interactivityæ•°æ®
            inter_zip = os.path.join(version_path, 'inference_max_interactivity.zip.zip')
            if os.path.exists(inter_zip):
                temp_dir = temp_dir_base + "_inter"
                inter_file = self.extract_zip_file(inter_zip, temp_dir)
                if inter_file:
                    data['interactivity'] = pd.read_csv(inter_file)

            # åŠ è½½mergedæ•°æ®
            merged_zip = os.path.join(version_path, 'inference_max_merged.zip.zip')
            if os.path.exists(merged_zip):
                temp_dir = temp_dir_base + "_merged"
                merged_file = self.extract_zip_file(merged_zip, temp_dir)
                if merged_file:
                    data['merged'] = pd.read_csv(merged_file)

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_dir in [temp_dir_base + "_e2e", temp_dir_base + "_inter", temp_dir_base + "_merged"]:
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir)

            return data

        except Exception as e:
            print(f"åŠ è½½ç‰ˆæœ¬ {version} æ•°æ®å¤±è´¥: {str(e)}")
            return None

    def analyze_version_data(self, version, data):
        """åˆ†æå•ä¸ªç‰ˆæœ¬çš„æ•°æ®"""
        analysis = {
            'version': version,
            'metadata': data['metadata'] if 'metadata' in data else None,
            'data_stats': {}
        }

        # åˆ†æe2eæ•°æ®
        if 'e2e' in data and data['e2e'] is not None:
            df = data['e2e']
            analysis['data_stats']['e2e'] = {
                'records': len(df),
                'columns': list(df.columns),
                'models': df['model_name'].unique().tolist() if 'model_name' in df.columns else [],
                'sequences': df['sequence_length'].unique().tolist() if 'sequence_length' in df.columns else [],
                'hw_keys': df['hwKey'].unique().tolist() if 'hwKey' in df.columns else [],
                'precisions': df['precision'].unique().tolist() if 'precision' in df.columns else [],
                'unique_combinations': len(df.groupby(['model_name', 'sequence_length', 'conc', 'hwKey', 'precision', 'tp'])) if all(col in df.columns for col in ['model_name', 'sequence_length', 'conc', 'hwKey', 'precision', 'tp']) else 0
            }

        # åˆ†æinteractivityæ•°æ®
        if 'interactivity' in data and data['interactivity'] is not None:
            df = data['interactivity']
            analysis['data_stats']['interactivity'] = {
                'records': len(df),
                'columns': list(df.columns),
                'models': df['model_name'].unique().tolist() if 'model_name' in df.columns else [],
                'sequences': df['sequence_length'].unique().tolist() if 'sequence_length' in df.columns else [],
                'hw_keys': df['hwKey'].unique().tolist() if 'hwKey' in df.columns else [],
                'precisions': df['precision'].unique().tolist() if 'precision' in df.columns else [],
                'unique_combinations': len(df.groupby(['model_name', 'sequence_length', 'conc', 'hwKey', 'precision', 'tp'])) if all(col in df.columns for col in ['model_name', 'sequence_length', 'conc', 'hwKey', 'precision', 'tp']) else 0
            }

        # åˆ†æmergedæ•°æ®
        if 'merged' in data and data['merged'] is not None:
            df = data['merged']
            analysis['data_stats']['merged'] = {
                'records': len(df),
                'columns': list(df.columns),
                'models': df['model_name'].unique().tolist() if 'model_name' in df.columns else [],
                'sequences': df['sequence_length'].unique().tolist() if 'sequence_length' in df.columns else [],
                'hw_keys': df['hwKey'].unique().tolist() if 'hwKey' in df.columns else [],
                'precisions': df['precision'].unique().tolist() if 'precision' in df.columns else [],
                'unique_combinations': len(df.groupby(['model_name', 'sequence_length', 'conc', 'hwKey', 'precision', 'tp'])) if all(col in df.columns for col in ['model_name', 'sequence_length', 'conc', 'hwKey', 'precision', 'tp']) else 0
            }

        return analysis

    def compare_versions(self, analysis1, analysis2):
        """æ¯”è¾ƒä¸¤ä¸ªç‰ˆæœ¬çš„åˆ†æç»“æœ"""
        comparison = {
            'version1': analysis1['version'],
            'version2': analysis2['version'],
            'differences': {}
        }

        # æ¯”è¾ƒæ•°æ®ç»Ÿè®¡
        for data_type in ['e2e', 'interactivity', 'merged']:
            if data_type in analysis1['data_stats'] and data_type in analysis2['data_stats']:
                stats1 = analysis1['data_stats'][data_type]
                stats2 = analysis2['data_stats'][data_type]

                diff = {}

                # æ¯”è¾ƒè®°å½•æ•°
                if stats1['records'] != stats2['records']:
                    diff['records'] = f"{stats1['records']} â†’ {stats2['records']}"

                # æ¯”è¾ƒå”¯ä¸€ç»„åˆæ•°
                if stats1['unique_combinations'] != stats2['unique_combinations']:
                    diff['unique_combinations'] = f"{stats1['unique_combinations']} â†’ {stats2['unique_combinations']}"

                # æ¯”è¾ƒæ¨¡å‹åˆ—è¡¨
                if set(stats1['models']) != set(stats2['models']):
                    diff['models'] = {
                        'only_in_v1': list(set(stats1['models']) - set(stats2['models'])),
                        'only_in_v2': list(set(stats2['models']) - set(stats1['models']))
                    }

                # æ¯”è¾ƒåºåˆ—é•¿åº¦åˆ—è¡¨
                if set(stats1['sequences']) != set(stats2['sequences']):
                    diff['sequences'] = {
                        'only_in_v1': list(set(stats1['sequences']) - set(stats2['sequences'])),
                        'only_in_v2': list(set(stats2['sequences']) - set(stats1['sequences']))
                    }

                # æ¯”è¾ƒç¡¬ä»¶å¹³å°åˆ—è¡¨
                if set(stats1['hw_keys']) != set(stats2['hw_keys']):
                    diff['hw_keys'] = {
                        'only_in_v1': list(set(stats1['hw_keys']) - set(stats2['hw_keys'])),
                        'only_in_v2': list(set(stats2['hw_keys']) - set(stats1['hw_keys']))
                    }

                # æ¯”è¾ƒç²¾åº¦åˆ—è¡¨
                if set(stats1['precisions']) != set(stats2['precisions']):
                    diff['precisions'] = {
                        'only_in_v1': list(set(stats1['precisions']) - set(stats2['precisions'])),
                        'only_in_v2': list(set(stats2['precisions']) - set(stats1['precisions']))
                    }

                if diff:
                    comparison['differences'][data_type] = diff

        return comparison

    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´çš„ç‰ˆæœ¬æ•°æ®éªŒè¯"""
        print("ğŸ” å¼€å§‹è¯¦ç»†çš„ç‰ˆæœ¬æ•°æ®éªŒè¯åˆ†æ...")

        # å‘ç°ç‰ˆæœ¬
        self.discover_versions()

        if len(self.versions) < 2:
            print("âŒ ç‰ˆæœ¬æ•°é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå¯¹æ¯”åˆ†æ")
            return

        # åˆ†ææ¯ä¸ªç‰ˆæœ¬
        all_analyses = []
        for version in self.versions:
            print(f"\nğŸ“Š åˆ†æç‰ˆæœ¬: {version}")
            data = self.load_version_data(version)
            if data:
                analysis = self.analyze_version_data(version, data)
                all_analyses.append(analysis)

                # æ‰“å°åŸºæœ¬ç»Ÿè®¡
                for data_type in ['e2e', 'interactivity', 'merged']:
                    if data_type in analysis['data_stats']:
                        stats = analysis['data_stats'][data_type]
                        print(f"  {data_type}: {stats['records']} æ¡è®°å½•, {stats['unique_combinations']} ä¸ªå”¯ä¸€ç»„åˆ")

        # æ¯”è¾ƒç‰ˆæœ¬
        print(f"\nğŸ” æ¯”è¾ƒç‰ˆæœ¬é—´çš„å·®å¼‚...")
        for i in range(len(all_analyses) - 1):
            comparison = self.compare_versions(all_analyses[i], all_analyses[i + 1])
            print(f"\nğŸ“‹ æ¯”è¾ƒ {comparison['version1']} vs {comparison['version2']}:")

            if not comparison['differences']:
                print("  âœ… æ— å·®å¼‚")
            else:
                for data_type, diff in comparison['differences'].items():
                    print(f"  ğŸ”¹ {data_type} æ•°æ®å·®å¼‚:")
                    for key, value in diff.items():
                        print(f"    {key}: {value}")

        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        self.save_detailed_report(all_analyses)

    def save_detailed_report(self, analyses):
        """ä¿å­˜è¯¦ç»†çš„åˆ†ææŠ¥å‘Š"""
        output_dir = "version_data_verification"
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        print(f"\nğŸ’¾ ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ° {output_dir}/")

        # ä¿å­˜JSONæ ¼å¼çš„å®Œæ•´åˆ†æ
        json_file = os.path.join(output_dir, f"detailed_version_analysis_{timestamp}.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(analyses, f, ensure_ascii=False, indent=2)

        print(f"  ğŸ“„ è¯¦ç»†åˆ†æ: {json_file}")

        # ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š
        md_file = os.path.join(output_dir, f"version_analysis_report_{timestamp}.md")
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write("# ç‰ˆæœ¬æ•°æ®éªŒè¯åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"**åˆ†æç‰ˆæœ¬æ•°**: {len(self.versions)}\n\n")
            f.write(f"**ç‰ˆæœ¬åˆ—è¡¨**:\n")
            for version in self.versions:
                f.write(f"- {version}\n")
            f.write("\n")

            for analysis in analyses:
                f.write(f"## ç‰ˆæœ¬: {analysis['version']}\n\n")

                if analysis['metadata']:
                    f.write(f"**æŠ“å–æ—¶é—´**: {analysis['metadata'].get('pipeline_start_time', 'N/A')}\n")
                    f.write(f"**ç®¡é“ID**: {analysis['metadata'].get('pipeline_id', 'N/A')}\n\n")

                for data_type, stats in analysis['data_stats'].items():
                    f.write(f"### {data_type.upper()} æ•°æ®\n\n")
                    f.write(f"- **è®°å½•æ•°**: {stats['records']}\n")
                    f.write(f"- **å”¯ä¸€ç»„åˆæ•°**: {stats['unique_combinations']}\n")
                    f.write(f"- **æ¨¡å‹æ•°é‡**: {len(stats['models'])}\n")
                    f.write(f"- **åºåˆ—é•¿åº¦æ•°é‡**: {len(stats['sequences'])}\n")
                    f.write(f"- **ç¡¬ä»¶å¹³å°æ•°é‡**: {len(stats['hw_keys'])}\n")
                    f.write(f"- **ç²¾åº¦ç±»å‹æ•°é‡**: {len(stats['precisions'])}\n\n")

        print(f"  ğŸ“– MarkdownæŠ¥å‘Š: {md_file}")
        return output_dir

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹éªŒè¯ç‰ˆæœ¬æ•°æ®çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§")

    verifier = VersionDataVerifier()
    verifier.run_full_analysis()

    print(f"\nâœ… éªŒè¯å®Œæˆï¼")

if __name__ == "__main__":
    main()