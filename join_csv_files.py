#!/usr/bin/env python3
import csv
import os
from collections import defaultdict
from datetime import datetime

def read_csv_file(filepath):
    """è¯»å–CSVæ–‡ä»¶å¹¶è¿”å›å­—å…¸æ•°æ®"""
    data = []
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                data.append(row)
        return data
    except Exception as e:
        print(f"Error reading {filepath}: {e}")
        return []

def create_key_index(data, key_fields):
    """åŸºäºæŒ‡å®šé”®å­—æ®µåˆ›å»ºç´¢å¼•"""
    index = defaultdict(list)

    for row in data:
        # åˆ›å»ºå¤åˆé”®
        key_parts = []
        for field in key_fields:
            key_parts.append(row.get(field, ''))

        key = '|'.join(key_parts)
        index[key].append(row)

    return index

def join_csv_files(e2e_data, interactivity_data, key_fields):
    """æ‰§è¡ŒåŸºäºå¤šé”®çš„joinæ“ä½œ"""
    print(f"ğŸ”„ Creating index for E2E data...")
    e2e_index = create_key_index(e2e_data, key_fields)

    print(f"ğŸ”„ Creating index for Interactivity data...")
    interactivity_index = create_key_index(interactivity_data, key_fields)

    print(f"ğŸ“Š E2E unique keys: {len(e2e_index)}")
    print(f"ğŸ“Š Interactivity unique keys: {len(interactivity_index)}")

    # æ‰§è¡Œjoinæ“ä½œ
    joined_data = []
    matched_keys = 0
    e2e_only_keys = 0
    inter_only_keys = 0

    # é¦–å…ˆå¤„ç†E2Eæ•°æ®ä½œä¸ºåŸºç¡€
    for key, e2e_rows in e2e_index.items():
        if key in interactivity_index:
            # æ‰¾åˆ°åŒ¹é…çš„è®°å½•
            inter_rows = interactivity_index[key]

            # å¤„ç†å¤šå¯¹å¤šå…³ç³»ï¼ˆè™½ç„¶ç†è®ºä¸Šåº”è¯¥æ˜¯ä¸€å¯¹ä¸€ï¼‰
            for e2e_row in e2e_rows:
                for inter_row in inter_rows:
                    # åˆ›å»ºåˆå¹¶åçš„è¡Œ
                    joined_row = e2e_row.copy()

                    # é‡å‘½åE2Eçš„xå’Œyå­—æ®µ
                    if 'x' in e2e_row:
                        joined_row['e2e_x'] = e2e_row['x']
                        del joined_row['x']

                    if 'y' in e2e_row:
                        joined_row['e2e_y'] = e2e_row['y']
                        del joined_row['y']

                    # æ·»åŠ Interactivityçš„xå’Œyå­—æ®µ
                    if 'x' in inter_row:
                        joined_row['inter_x'] = inter_row['x']

                    if 'y' in inter_row:
                        joined_row['inter_y'] = inter_row['y']

                    joined_data.append(joined_row)

            matched_keys += 1
        else:
            # E2Eç‹¬æœ‰çš„è®°å½•
            for e2e_row in e2e_rows:
                joined_row = e2e_row.copy()

                # é‡å‘½åE2Eçš„xå’Œyå­—æ®µ
                if 'x' in e2e_row:
                    joined_row['e2e_x'] = e2e_row['x']
                    del joined_row['x']

                if 'y' in e2e_row:
                    joined_row['e2e_y'] = e2e_row['y']
                    del joined_row['y']

                # æ·»åŠ ç©ºçš„Interactivityå­—æ®µ
                joined_row['inter_x'] = ''
                joined_row['inter_y'] = ''

                joined_data.append(joined_row)

            e2e_only_keys += 1

    # å¤„ç†Interactivityç‹¬æœ‰çš„è®°å½•
    for key, inter_rows in interactivity_index.items():
        if key not in e2e_index:
            for inter_row in inter_rows:
                # åˆ›å»ºåŸºç¡€è¡Œï¼ˆä½¿ç”¨Interactivityæ•°æ®ï¼Œä½†å…¶ä»–å­—æ®µç”¨ç©ºå€¼ï¼‰
                joined_row = {}

                # å¤åˆ¶æ‰€æœ‰å­—æ®µ
                for field in inter_row:
                    if field in ['x', 'y']:
                        continue  # è·³è¿‡xå’Œyï¼Œç¨åå¤„ç†
                    joined_row[field] = inter_row[field]

                # æ·»åŠ ç©ºçš„E2Eå­—æ®µ
                joined_row['e2e_x'] = ''
                joined_row['e2e_y'] = ''

                # æ·»åŠ Interactivityçš„xå’Œyå­—æ®µ
                if 'x' in inter_row:
                    joined_row['inter_x'] = inter_row['x']

                if 'y' in inter_row:
                    joined_row['inter_y'] = inter_row['y']

                joined_data.append(joined_row)

            inter_only_keys += 1

    print(f"âœ… Matched keys: {matched_keys}")
    print(f"âš ï¸  E2E only keys: {e2e_only_keys}")
    print(f"âš ï¸  Interactivity only keys: {inter_only_keys}")
    print(f"ğŸ“Š Total joined records: {len(joined_data)}")

    return joined_data, {
        'matched_keys': matched_keys,
        'e2e_only_keys': e2e_only_keys,
        'inter_only_keys': inter_only_keys,
        'total_records': len(joined_data)
    }

def define_output_columns(base_columns):
    """å®šä¹‰è¾“å‡ºåˆ—çš„é¡ºåº"""
    # åŸºç¡€åˆ—ï¼ˆæ¥è‡ªE2Eæ–‡ä»¶ï¼Œé™¤äº†xå’Œyï¼‰
    exclude_columns = ['x', 'y']
    base_cols = [col for col in base_columns if col not in exclude_columns]

    # æ·»åŠ æ–°çš„åˆ—
    new_columns = ['e2e_x', 'e2e_y', 'inter_x', 'inter_y']

    return base_cols + new_columns

def save_joined_csv(data, columns, output_file):
    """ä¿å­˜åˆå¹¶åçš„CSVæ–‡ä»¶"""
    try:
        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=columns)
            writer.writeheader()
            writer.writerows(data)

        print(f"âœ… Joined CSV saved: {output_file}")
        return True
    except Exception as e:
        print(f"âŒ Error saving joined CSV: {e}")
        return False

def validate_joined_data(data, key_fields):
    """éªŒè¯åˆå¹¶åçš„æ•°æ®è´¨é‡"""
    print("\nğŸ” Validating joined data...")

    # ç»Ÿè®¡å„å­—æ®µçš„æ•°æ®å®Œæ•´æ€§
    field_stats = {}
    for field in ['e2e_x', 'e2e_y', 'inter_x', 'inter_y']:
        non_empty = sum(1 for row in data if row.get(field, '').strip())
        field_stats[field] = {
            'total': len(data),
            'non_empty': non_empty,
            'empty': len(data) - non_empty,
            'completeness': (non_empty / len(data)) * 100 if data else 0
        }

    for field, stats in field_stats.items():
        print(f"ğŸ“Š {field}: {stats['non_empty']}/{stats['total']} ({stats['completeness']:.1f}%) complete")

    # æ£€æŸ¥é”®å­—æ®µçš„å®Œæ•´æ€§
    key_completeness = {}
    for field in key_fields:
        non_empty = sum(1 for row in data if row.get(field, '').strip())
        key_completeness[field] = (non_empty / len(data)) * 100 if data else 0

    print(f"\nğŸ”‘ Key field completeness:")
    for field, completeness in key_completeness.items():
        print(f"   {field}: {completeness:.1f}%")

    return field_stats

def create_join_summary(stats, validation_stats, output_file):
    """åˆ›å»ºjoinæ“ä½œçš„æ‘˜è¦æŠ¥å‘Š"""
    summary = {
        'join_timestamp': datetime.now().isoformat(),
        'output_file': output_file,
        'join_statistics': stats,
        'validation_statistics': validation_stats
    }

    summary_text = f"""# CSVæ–‡ä»¶åˆå¹¶æŠ¥å‘Š

## ğŸ“Š åˆå¹¶ç»Ÿè®¡
- **åˆå¹¶æ—¶é—´**: {summary['join_timestamp']}
- **è¾“å‡ºæ–‡ä»¶**: {output_file}
- **åŒ¹é…çš„é”®æ•°é‡**: {stats['matched_keys']}
- **ä»…E2Eçš„é”®æ•°é‡**: {stats['e2e_only_keys']}
- **ä»…Interactivityçš„é”®æ•°é‡**: {stats['inter_only_keys']}
- **æ€»è®°å½•æ•°**: {stats['total_records']}

## ğŸ“‹ æ•°æ®å®Œæ•´æ€§éªŒè¯

### x/yå­—æ®µå®Œæ•´æ€§
"""

    for field, field_stats in validation_stats.items():
        completeness = field_stats['completeness']
        summary_text += f"- **{field}**: {field_stats['non_empty']}/{field_stats['total']} ({completeness:.1f}%)\n"

    summary_text += f"""
## ğŸ”„ åˆå¹¶è¯´æ˜
- **Joiné”®**: model_name, sequence_length, conc, hwKey, precision, tp
- **åŸºç¡€æ•°æ®**: æ¥è‡ªE2E CSVæ–‡ä»¶
- **é‡å‘½åå­—æ®µ**:
  - E2Eçš„x â†’ e2e_x
  - E2Eçš„y â†’ e2e_y
  - Interactivityçš„x â†’ inter_x
  - Interactivityçš„y â†’ inter_y

## ğŸ“„ è¾“å‡ºæ–‡ä»¶è¯´æ˜
åˆå¹¶åçš„CSVæ–‡ä»¶åŒ…å«ï¼š
- æ‰€æœ‰æ¥è‡ªE2Eæ–‡ä»¶çš„åŸå§‹åˆ—ï¼ˆé™¤äº†xå’Œyï¼‰
- 4ä¸ªæ–°åˆ—ï¼še2e_x, e2e_y, inter_x, inter_y
- å¯¹äºæ— æ³•åŒ¹é…çš„è®°å½•ï¼Œç›¸åº”å­—æ®µä¸ºç©ºå€¼

## ğŸ” ä½¿ç”¨å»ºè®®
1. **å®Œæ•´åŒ¹é…è®°å½•**: å¯ä»¥åŒæ—¶åˆ†æe2eå’Œinteractivityçš„æ€§èƒ½æŒ‡æ ‡
2. **ä»…E2Eè®°å½•**: åªæœ‰ç«¯åˆ°ç«¯æ€§èƒ½æ•°æ®
3. **ä»…Interactivityè®°å½•**: åªæœ‰äº¤äº’å¼æ€§èƒ½æ•°æ®
4. **æ•°æ®åˆ†æ**: å¯ä»¥æ¯”è¾ƒä¸¤ç§åœºæ™¯ä¸‹çš„æ€§èƒ½å·®å¼‚

---

*æ­¤æ–‡ä»¶ç”± E2E å’Œ Interactivity CSV åˆå¹¶ç”Ÿæˆ*
"""

    return summary, summary_text

def main():
    e2e_file = 'json_data/inference_max_e2e.csv'
    interactivity_file = 'json_data/inference_max_interactivity.csv'
    output_file = 'json_data/inference_max_merged.csv'
    summary_file = 'json_data/CSV_MERGE_REPORT.md'

    # å®šä¹‰joinçš„é”®å­—æ®µ
    key_fields = ['model_name', 'sequence_length', 'conc', 'hwKey', 'precision', 'tp']

    print("ğŸš€ Starting CSV file merge operation...")

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(e2e_file):
        print(f"âŒ E2E file not found: {e2e_file}")
        return

    if not os.path.exists(interactivity_file):
        print(f"âŒ Interactivity file not found: {interactivity_file}")
        return

    # è¯»å–CSVæ–‡ä»¶
    print(f"ğŸ“– Reading E2E file: {e2e_file}")
    e2e_data = read_csv_file(e2e_file)
    print(f"   Loaded {len(e2e_data)} records")

    print(f"ğŸ“– Reading Interactivity file: {interactivity_file}")
    interactivity_data = read_csv_file(interactivity_file)
    print(f"   Loaded {len(interactivity_data)} records")

    # æ‰§è¡Œjoinæ“ä½œ
    print(f"\nğŸ”„ Joining files on keys: {', '.join(key_fields)}")
    joined_data, stats = join_csv_files(e2e_data, interactivity_data, key_fields)

    if not joined_data:
        print("âŒ No data to save")
        return

    # å®šä¹‰è¾“å‡ºåˆ—
    base_columns = e2e_data[0].keys() if e2e_data else []
    output_columns = define_output_columns(base_columns)

    print(f"ğŸ“‹ Output columns: {len(output_columns)}")

    # ä¿å­˜åˆå¹¶åçš„æ–‡ä»¶
    if save_joined_csv(joined_data, output_columns, output_file):
        # éªŒè¯æ•°æ®è´¨é‡
        validation_stats = validate_joined_data(joined_data, key_fields)

        # åˆ›å»ºæ‘˜è¦æŠ¥å‘Š
        summary, summary_text = create_join_summary(stats, validation_stats, output_file)

        # ä¿å­˜æ‘˜è¦æŠ¥å‘Š
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary_text)

        # æ˜¾ç¤ºç»“æœ
        file_size = os.path.getsize(output_file)
        print(f"\nğŸ‰ CSV merge completed successfully!")
        print(f"ğŸ“„ Output file: {output_file}")
        print(f"ğŸ“Š File size: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
        print(f"ğŸ“ˆ Total records: {len(joined_data):,}")
        print(f"ğŸ“‹ Columns: {len(output_columns)}")
        print(f"ğŸ“Š Match rate: {(stats['matched_keys']/(stats['matched_keys']+stats['e2e_only_keys']+stats['inter_only_keys'])*100):.1f}%")
        print(f"ğŸ“‹ Summary report: {summary_file}")

        # æ˜¾ç¤ºåˆ—é¢„è§ˆ
        print(f"\nğŸ“‹ Column preview:")
        print("Columns:", ", ".join(output_columns[:10]) + "..." if len(output_columns) > 10 else ", ".join(output_columns))

        # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        print(f"\nğŸ“Š Data preview (first 3 records):")
        for i, row in enumerate(joined_data[:3]):
            print(f"Record {i+1}:")
            print(f"  Model: {row.get('model_name', 'N/A')}")
            print(f"  Sequence: {row.get('sequence_length', 'N/A')}")
            print(f"  Hardware: {row.get('hwKey', 'N/A')}")
            print(f"  Concurrency: {row.get('conc', 'N/A')}")
            print(f"  E2E coords: ({row.get('e2e_x', 'N/A')}, {row.get('e2e_y', 'N/A')})")
            print(f"  Inter coords: ({row.get('inter_x', 'N/A')}, {row.get('inter_y', 'N/A')})")
            print()

if __name__ == "__main__":
    main()