[
  {
    "version": "version_20251023_165452",
    "metadata": {
      "pipeline_id": "20251023_165452",
      "timestamp": "2025-10-23T16:54:52.132999",
      "archived_files": [
        "inference_max_interactivity.csv",
        "inference_max_e2e.csv",
        "inference_max_merged.csv",
        "SEPARATED_CSV_CONVERSION_REPORT.md",
        "CSV_MERGE_REPORT.md"
      ],
      "config": {
        "source": {
          "base_url": "https://inferencemax.semianalysis.com/",
          "timeout": 600,
          "retry_attempts": 3,
          "retry_delay": 5
        },
        "targets": {
          "models": [
            "Llama 3.3 70B Instruct",
            "gpt-oss 120B",
            "DeepSeek R1 0528"
          ],
          "sequences": [
            "1K / 1K",
            "1K / 8K",
            "8K / 1K"
          ]
        },
        "paths": {
          "base_dir": "/root/semi-bench",
          "raw_data_dir": "json_data/raw_json_files",
          "output_dir": "json_data",
          "archive_dir": "inference_max_pipeline/data_archive",
          "log_dir": "inference_max_pipeline/logs",
          "report_dir": "inference_max_pipeline/reports"
        },
        "cleanup": {
          "min_file_size": 1024,
          "require_numeric_data": true,
          "remove_empty_files": true
        },
        "versioning": {
          "enabled": true,
          "max_versions": 30,
          "compression": true,
          "date_format": "%Y%m%d_%H%M%S"
        },
        "logging": {
          "level": "INFO",
          "max_file_size": "10MB",
          "backup_count": 5,
          "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        },
        "monitoring": {
          "enabled": true,
          "check_data_quality": true,
          "expected_min_records": 1000,
          "alert_on_failure": true
        },
        "notifications": {
          "email": {
            "enabled": false,
            "smtp_server": "",
            "smtp_port": 587,
            "username": "",
            "password": "",
            "recipients": []
          },
          "webhook": {
            "enabled": false,
            "url": ""
          }
        },
        "scheduling": {
          "enabled": false,
          "cron_expression": "0 2 * * *",
          "timezone": "UTC"
        },
        "performance": {
          "max_concurrent_downloads": 3,
          "request_timeout": 30,
          "page_load_timeout": 10
        },
        "output": {
          "final_csv": "inference_max_latest.csv",
          "prefix": "inference_max_",
          "timestamp_format": "%Y%m%d_%H%M%S"
        }
      }
    },
    "data_stats": {
      "e2e": {
        "records": 1339,
        "columns": [
          "model_name",
          "sequence_length",
          "conc",
          "costh_roof",
          "costh_y",
          "costn_roof",
          "costn_y",
          "costr_roof",
          "costr_y",
          "hwKey",
          "precision",
          "tp",
          "tpPerGpu_roof",
          "tpPerGpu_y",
          "tpPerMw_roof",
          "tpPerMw_y",
          "x",
          "y"
        ],
        "models": [
          "gpt-oss 120B",
          "Llama 3.3 70B Instruct",
          "DeepSeek R1 0528"
        ],
        "sequences": [
          "1k-1k",
          "1k-8k",
          "8k-1k"
        ],
        "hw_keys": [
          "mi300x",
          "mi355x",
          "h200",
          "h200_trt",
          "b200",
          "mi325x",
          "h100",
          "b200_trt",
          "gb200",
          "gb200_mtp"
        ],
        "precisions": [
          "fp4",
          "fp8"
        ],
        "unique_combinations": 1339
      },
      "interactivity": {
        "records": 1339,
        "columns": [
          "model_name",
          "sequence_length",
          "conc",
          "costh_roof",
          "costh_y",
          "costn_roof",
          "costn_y",
          "costr_roof",
          "costr_y",
          "hwKey",
          "precision",
          "tp",
          "tpPerGpu_roof",
          "tpPerGpu_y",
          "tpPerMw_roof",
          "tpPerMw_y",
          "x",
          "y"
        ],
        "models": [
          "gpt-oss 120B",
          "Llama 3.3 70B Instruct",
          "DeepSeek R1 0528"
        ],
        "sequences": [
          "1k-8k",
          "1k-1k",
          "8k-1k"
        ],
        "hw_keys": [
          "mi325x",
          "b200",
          "h200_trt",
          "h100",
          "mi300x",
          "mi355x",
          "h200",
          "b200_trt",
          "gb200",
          "gb200_mtp"
        ],
        "precisions": [
          "fp4",
          "fp8"
        ],
        "unique_combinations": 1339
      },
      "merged": {
        "records": 1339,
        "columns": [
          "model_name",
          "sequence_length",
          "conc",
          "costh_roof",
          "costh_y",
          "costn_roof",
          "costn_y",
          "costr_roof",
          "costr_y",
          "hwKey",
          "precision",
          "tp",
          "tpPerGpu_roof",
          "tpPerGpu_y",
          "tpPerMw_roof",
          "tpPerMw_y",
          "e2e_x",
          "e2e_y",
          "inter_x",
          "inter_y"
        ],
        "models": [
          "gpt-oss 120B",
          "Llama 3.3 70B Instruct",
          "DeepSeek R1 0528"
        ],
        "sequences": [
          "1k-1k",
          "1k-8k",
          "8k-1k"
        ],
        "hw_keys": [
          "mi300x",
          "mi355x",
          "h200",
          "h200_trt",
          "b200",
          "mi325x",
          "h100",
          "b200_trt",
          "gb200",
          "gb200_mtp"
        ],
        "precisions": [
          "fp4",
          "fp8"
        ],
        "unique_combinations": 1339
      }
    }
  },
  {
    "version": "version_20251024_010002",
    "metadata": {
      "pipeline_id": "20251024_010002",
      "timestamp": "2025-10-24T01:00:02.098097",
      "archived_files": [
        "inference_max_interactivity.csv",
        "inference_max_e2e.csv",
        "inference_max_merged.csv",
        "SEPARATED_CSV_CONVERSION_REPORT.md",
        "CSV_MERGE_REPORT.md"
      ],
      "config": {
        "source": {
          "base_url": "https://inferencemax.semianalysis.com/",
          "timeout": 600,
          "retry_attempts": 3,
          "retry_delay": 5
        },
        "targets": {
          "models": [
            "Llama 3.3 70B Instruct",
            "gpt-oss 120B",
            "DeepSeek R1 0528"
          ],
          "sequences": [
            "1K / 1K",
            "1K / 8K",
            "8K / 1K"
          ]
        },
        "paths": {
          "base_dir": "/root/semi-bench",
          "raw_data_dir": "json_data/raw_json_files",
          "output_dir": "json_data",
          "archive_dir": "inference_max_pipeline/data_archive",
          "log_dir": "inference_max_pipeline/logs",
          "report_dir": "inference_max_pipeline/reports"
        },
        "cleanup": {
          "min_file_size": 1024,
          "require_numeric_data": true,
          "remove_empty_files": true
        },
        "versioning": {
          "enabled": true,
          "max_versions": 30,
          "compression": true,
          "date_format": "%Y%m%d_%H%M%S"
        },
        "logging": {
          "level": "INFO",
          "max_file_size": "10MB",
          "backup_count": 5,
          "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        },
        "monitoring": {
          "enabled": true,
          "check_data_quality": true,
          "expected_min_records": 1000,
          "alert_on_failure": true
        },
        "notifications": {
          "email": {
            "enabled": false,
            "smtp_server": "",
            "smtp_port": 587,
            "username": "",
            "password": "",
            "recipients": []
          },
          "webhook": {
            "enabled": false,
            "url": ""
          }
        },
        "scheduling": {
          "enabled": true,
          "cron_expression": "0 1 * * *",
          "timezone": "UTC"
        },
        "performance": {
          "max_concurrent_downloads": 3,
          "request_timeout": 30,
          "page_load_timeout": 10
        },
        "output": {
          "final_csv": "inference_max_latest.csv",
          "prefix": "inference_max_",
          "timestamp_format": "%Y%m%d_%H%M%S"
        }
      }
    },
    "data_stats": {
      "e2e": {
        "records": 1339,
        "columns": [
          "model_name",
          "sequence_length",
          "conc",
          "costh_roof",
          "costh_y",
          "costn_roof",
          "costn_y",
          "costr_roof",
          "costr_y",
          "hwKey",
          "precision",
          "tp",
          "tpPerGpu_roof",
          "tpPerGpu_y",
          "tpPerMw_roof",
          "tpPerMw_y",
          "x",
          "y"
        ],
        "models": [
          "gpt-oss 120B",
          "Llama 3.3 70B Instruct",
          "DeepSeek R1 0528"
        ],
        "sequences": [
          "1k-1k",
          "1k-8k",
          "8k-1k"
        ],
        "hw_keys": [
          "mi300x",
          "mi355x",
          "h200",
          "h200_trt",
          "b200",
          "mi325x",
          "h100",
          "b200_trt",
          "gb200",
          "gb200_mtp"
        ],
        "precisions": [
          "fp4",
          "fp8"
        ],
        "unique_combinations": 1339
      },
      "interactivity": {
        "records": 1339,
        "columns": [
          "model_name",
          "sequence_length",
          "conc",
          "costh_roof",
          "costh_y",
          "costn_roof",
          "costn_y",
          "costr_roof",
          "costr_y",
          "hwKey",
          "precision",
          "tp",
          "tpPerGpu_roof",
          "tpPerGpu_y",
          "tpPerMw_roof",
          "tpPerMw_y",
          "x",
          "y"
        ],
        "models": [
          "gpt-oss 120B",
          "Llama 3.3 70B Instruct",
          "DeepSeek R1 0528"
        ],
        "sequences": [
          "1k-8k",
          "1k-1k",
          "8k-1k"
        ],
        "hw_keys": [
          "mi325x",
          "b200",
          "h200_trt",
          "h100",
          "mi300x",
          "mi355x",
          "h200",
          "b200_trt",
          "gb200",
          "gb200_mtp"
        ],
        "precisions": [
          "fp4",
          "fp8"
        ],
        "unique_combinations": 1339
      },
      "merged": {
        "records": 1339,
        "columns": [
          "model_name",
          "sequence_length",
          "conc",
          "costh_roof",
          "costh_y",
          "costn_roof",
          "costn_y",
          "costr_roof",
          "costr_y",
          "hwKey",
          "precision",
          "tp",
          "tpPerGpu_roof",
          "tpPerGpu_y",
          "tpPerMw_roof",
          "tpPerMw_y",
          "e2e_x",
          "e2e_y",
          "inter_x",
          "inter_y"
        ],
        "models": [
          "gpt-oss 120B",
          "Llama 3.3 70B Instruct",
          "DeepSeek R1 0528"
        ],
        "sequences": [
          "1k-1k",
          "1k-8k",
          "8k-1k"
        ],
        "hw_keys": [
          "mi300x",
          "mi355x",
          "h200",
          "h200_trt",
          "b200",
          "mi325x",
          "h100",
          "b200_trt",
          "gb200",
          "gb200_mtp"
        ],
        "precisions": [
          "fp4",
          "fp8"
        ],
        "unique_combinations": 1339
      }
    }
  },
  {
    "version": "version_20251024_020006",
    "metadata": {
      "pipeline_id": "20251024_020006",
      "timestamp": "2025-10-24T02:00:06.762112",
      "archived_files": [
        "inference_max_interactivity.csv",
        "inference_max_e2e.csv",
        "inference_max_merged.csv",
        "SEPARATED_CSV_CONVERSION_REPORT.md",
        "CSV_MERGE_REPORT.md"
      ],
      "config": {
        "source": {
          "base_url": "https://inferencemax.semianalysis.com/",
          "timeout": 600,
          "retry_attempts": 3,
          "retry_delay": 5
        },
        "targets": {
          "models": [
            "Llama 3.3 70B Instruct",
            "gpt-oss 120B",
            "DeepSeek R1 0528"
          ],
          "sequences": [
            "1K / 1K",
            "1K / 8K",
            "8K / 1K"
          ]
        },
        "paths": {
          "base_dir": "/root/semi-bench",
          "raw_data_dir": "json_data/raw_json_files",
          "output_dir": "json_data",
          "archive_dir": "inference_max_pipeline/data_archive",
          "log_dir": "inference_max_pipeline/logs",
          "report_dir": "inference_max_pipeline/reports"
        },
        "cleanup": {
          "min_file_size": 1024,
          "require_numeric_data": true,
          "remove_empty_files": true
        },
        "versioning": {
          "enabled": true,
          "max_versions": 30,
          "compression": true,
          "date_format": "%Y%m%d_%H%M%S"
        },
        "logging": {
          "level": "INFO",
          "max_file_size": "10MB",
          "backup_count": 5,
          "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        },
        "monitoring": {
          "enabled": true,
          "check_data_quality": true,
          "expected_min_records": 1000,
          "alert_on_failure": true
        },
        "notifications": {
          "email": {
            "enabled": false,
            "smtp_server": "",
            "smtp_port": 587,
            "username": "",
            "password": "",
            "recipients": []
          },
          "webhook": {
            "enabled": false,
            "url": ""
          }
        },
        "scheduling": {
          "enabled": true,
          "cron_expression": "0 1 * * *",
          "timezone": "UTC"
        },
        "performance": {
          "max_concurrent_downloads": 3,
          "request_timeout": 30,
          "page_load_timeout": 10
        },
        "output": {
          "final_csv": "inference_max_latest.csv",
          "prefix": "inference_max_",
          "timestamp_format": "%Y%m%d_%H%M%S"
        }
      }
    },
    "data_stats": {
      "e2e": {
        "records": 1339,
        "columns": [
          "model_name",
          "sequence_length",
          "conc",
          "costh_roof",
          "costh_y",
          "costn_roof",
          "costn_y",
          "costr_roof",
          "costr_y",
          "hwKey",
          "precision",
          "tp",
          "tpPerGpu_roof",
          "tpPerGpu_y",
          "tpPerMw_roof",
          "tpPerMw_y",
          "x",
          "y"
        ],
        "models": [
          "gpt-oss 120B",
          "Llama 3.3 70B Instruct",
          "DeepSeek R1 0528"
        ],
        "sequences": [
          "1k-1k",
          "1k-8k",
          "8k-1k"
        ],
        "hw_keys": [
          "mi300x",
          "mi355x",
          "h200",
          "h200_trt",
          "b200",
          "mi325x",
          "h100",
          "b200_trt",
          "gb200",
          "gb200_mtp"
        ],
        "precisions": [
          "fp4",
          "fp8"
        ],
        "unique_combinations": 1339
      },
      "interactivity": {
        "records": 1339,
        "columns": [
          "model_name",
          "sequence_length",
          "conc",
          "costh_roof",
          "costh_y",
          "costn_roof",
          "costn_y",
          "costr_roof",
          "costr_y",
          "hwKey",
          "precision",
          "tp",
          "tpPerGpu_roof",
          "tpPerGpu_y",
          "tpPerMw_roof",
          "tpPerMw_y",
          "x",
          "y"
        ],
        "models": [
          "gpt-oss 120B",
          "Llama 3.3 70B Instruct",
          "DeepSeek R1 0528"
        ],
        "sequences": [
          "1k-8k",
          "1k-1k",
          "8k-1k"
        ],
        "hw_keys": [
          "mi325x",
          "b200",
          "h200_trt",
          "h100",
          "mi300x",
          "mi355x",
          "h200",
          "b200_trt",
          "gb200",
          "gb200_mtp"
        ],
        "precisions": [
          "fp4",
          "fp8"
        ],
        "unique_combinations": 1339
      },
      "merged": {
        "records": 1339,
        "columns": [
          "model_name",
          "sequence_length",
          "conc",
          "costh_roof",
          "costh_y",
          "costn_roof",
          "costn_y",
          "costr_roof",
          "costr_y",
          "hwKey",
          "precision",
          "tp",
          "tpPerGpu_roof",
          "tpPerGpu_y",
          "tpPerMw_roof",
          "tpPerMw_y",
          "e2e_x",
          "e2e_y",
          "inter_x",
          "inter_y"
        ],
        "models": [
          "gpt-oss 120B",
          "Llama 3.3 70B Instruct",
          "DeepSeek R1 0528"
        ],
        "sequences": [
          "1k-1k",
          "1k-8k",
          "8k-1k"
        ],
        "hw_keys": [
          "mi300x",
          "mi355x",
          "h200",
          "h200_trt",
          "b200",
          "mi325x",
          "h100",
          "b200_trt",
          "gb200",
          "gb200_mtp"
        ],
        "precisions": [
          "fp4",
          "fp8"
        ],
        "unique_combinations": 1339
      }
    }
  }
]