{
  "timestamp": 1761184315.741687,
  "url": "https://inferencemax.semianalysis.com/",
  "title": "InferenceMAX by SemiAnalysis",
  "dropdowns": {
    "model_dropdown_0": {
      "button_text": "gpt-oss 120B",
      "options": [
        "Llama 3.3 70B Instruct",
        "gpt-oss 120B",
        "DeepSeek R1 0528"
      ]
    },
    "isl_osl_dropdown_0": {
      "button_text": "1K / 1K",
      "options": []
    }
  },
  "combinations": [],
  "page_data": {
    "scripts": [
      "self.__next_f.push([1,\"0:{\\\"P\\\":null,\\\"b\\\":\\\"WmjRNftV1i21uehX8qT-_\\\",\\\"p\\\":\\\"\\\",\\\"c\\\":[\\\"\\\",\\\"\\\"],\\\"i\\\":false,\\\"f\\\":[[[\\\"\\\",{\\\"children\\\":[\\\"__PAGE__\\\",{}]},\\\"$undefined\\\",\\\"$undefined\\\",true],[\\\"\\\",[\\\"$\\\",\\\"$1\\\",\\\"c\\\",{\\\"children\\\":[[[\\\"$\\\",\\\"link\\\",\\\"0\\\",{\\\"rel\\\":\\\"stylesheet\\\",\\\"href\\\":\\\"/_next/static/chunks/49a2f8de51ac07bc.css\\\",\\\"precedence\\\":\\\"next\\\",\\\"crossOrigin\\\":\\\"$undefined\\\",\\\"nonce\\\":\\\"$undefined\\\"}],[\\\"$\\\",\\\"script\\\",\\\"script-0\\\",{\\\"src\\\":\\\"/_next/static/chunks/2a12f18bfe222317.js",
      "self.__next_f.push([1,\"17:I[62574,[\\\"/_next/static/chunks/2a12f18bfe222317.js\\\",\\\"/_next/static/chunks/b3da45e2aa9a8565.js\\\",\\\"/_next/static/chunks/6a7993b07cb97bb3.js\\\",\\\"/_next/static/chunks/246f2072837abfcb.js\\\",\\\"/_next/static/chunks/99af433a38a0e600.js\\\",\\\"/_next/static/chunks/8a7a36c3c3e49f7a.js\\\"],\\\"InferencePerformanceChart\\\"]\\n18:I[96875,[\\\"/_next/static/chunks/2a12f18bfe222317.js\\\",\\\"/_next/static/chunks/b3da45e2aa9a8565.js\\\",\\\"/_next/static/chunks/6a7993b07cb97bb3.js\\\",\\\"/_next/static",
      "self.__next_f.push([1,\"d mb-2\\\",\\\"children\\\":\\\"The fast cadence of software development and model releases makes comparing performance between setups difficult. Existing performance benchmarks quickly become obsolete because they are static, and participants often game the benchmarks with unrealistic, highly specific configurations.\\\"}]\\nc:[\\\"$\\\",\\\"p\\\",null,{\\\"className\\\":\\\"text-muted-foreground mb-2\\\",\\\"children\\\":[[\\\"$\\\",\\\"strong\\\",null,{\\\"children\\\":\\\"InferenceMAX\\\"}],\\\" addresses these issue",
      "self.__next_f.push([1,\"1e:{\\\"metadata\\\":[[\\\"$\\\",\\\"title\\\",\\\"0\\\",{\\\"children\\\":\\\"InferenceMAX by SemiAnalysis\\\"}],[\\\"$\\\",\\\"meta\\\",\\\"1\\\",{\\\"name\\\":\\\"description\\\",\\\"content\\\":\\\"InferenceMAX is the open-source AI inference benchmark that matches the rapid pace of modern AI development. Powered by one of the largest open-source GPU CI/CD fleets with NVIDIA GB200, AMD MI355X \\u0026 many more.\\\"}],[\\\"$\\\",\\\"link\\\",\\\"2\\\",{\\\"rel\\\":\\\"author\\\",\\\"href\\\":\\\"https://semianalysis.com\\\"}],[\\\"$\\\",\\\"meta\\\",\\\"3\\\",{",
      "self.__next_f.push([1,\"23:\\\"$1e:metadata\\\"\\n\"])"
    ]
  }
}