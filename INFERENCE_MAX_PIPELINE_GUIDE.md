# InferenceMAX è‡ªåŠ¨åŒ–æ•°æ®ç®¡é“ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨ InferenceMAX è‡ªåŠ¨åŒ–æ•°æ®ç®¡é“ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿå¯ä»¥å®šæœŸè‡ªåŠ¨æŠ“å–ã€å¤„ç†å’Œåˆå¹¶ InferenceMAX ç½‘ç«™çš„AIæ¨ç†æ€§èƒ½æ•°æ®ã€‚

### ğŸ”„ å®Œæ•´æµç¨‹

1. **ç½‘é¡µæ•°æ®çˆ¬å–** - ä» https://inferencemax.semianalysis.com/ è‡ªåŠ¨çˆ¬å–JSONæ•°æ®
2. **æ•°æ®æ¸…ç†** - ç§»é™¤æ— æ•ˆå’Œå°æ–‡ä»¶ï¼Œç¡®ä¿æ•°æ®è´¨é‡
3. **CSVè½¬æ¢** - å°†JSONæ•°æ®è½¬æ¢ä¸ºåˆ†ç¦»çš„interactivityå’Œe2e CSVæ–‡ä»¶
4. **æ•°æ®åˆå¹¶** - åŸºäºå¤šé”®å°†ä¸¤ä¸ªCSVæ–‡ä»¶åˆå¹¶ä¸ºæœ€ç»ˆæ•°æ®é›†
5. **ç‰ˆæœ¬å½’æ¡£** - ä¿å­˜å†å²ç‰ˆæœ¬ï¼Œæ”¯æŒæ•°æ®è¿½æº¯
6. **è‡ªåŠ¨è°ƒåº¦** - æ”¯æŒå®šæ—¶è‡ªåŠ¨æ‰§è¡Œ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…å’Œè®¾ç½®

```bash
# è¿è¡Œå®‰è£…è„šæœ¬
cd /root/semi-bench
python inference_max_pipeline/scripts/setup.py
```

å®‰è£…è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- æ£€æŸ¥Pythonç‰ˆæœ¬å’Œä¾èµ–
- å®‰è£…å¿…è¦çš„PythonåŒ…
- åˆ›å»ºç›®å½•ç»“æ„
- è®¾ç½®æ–‡ä»¶æƒé™
- æä¾›systemdæœåŠ¡å’Œcrontabé…ç½®

### 2. æ‰‹åŠ¨æ‰§è¡Œä¸€æ¬¡

```bash
# æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æ•°æ®ç®¡é“
python inference_max_pipeline/scripts/scheduler.py --once
```

### 3. è®¾ç½®å®šæ—¶æ‰§è¡Œ

#### æ–¹æ³•ä¸€: ä½¿ç”¨systemdæœåŠ¡ (æ¨è)

```bash
# å¯ç”¨systemdæœåŠ¡
sudo systemctl daemon-reload
sudo systemctl enable inference-max-pipeline
sudo systemctl start inference-max-pipeline

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
sudo systemctl status inference-max-pipeline

# æŸ¥çœ‹æ—¥å¿—
sudo journalctl -u inference-max-pipeline -f
```

#### æ–¹æ³•äºŒ: ä½¿ç”¨crontab

```bash
# ç¼–è¾‘crontab
crontab -e

# æ·»åŠ ä»¥ä¸‹è¡Œï¼ˆæ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œï¼‰
0 2 * * * cd /root/semi-bench && python inference_max_pipeline/scripts/scheduler.py --once >> inference_max_pipeline/logs/cron.log 2>&1
```

## ğŸ“ ç›®å½•ç»“æ„

```
inference_max_pipeline/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ pipeline_config.yaml          # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ pipeline_YYYYMMDD_HHMMSS.log  # æ¯æ¬¡æ‰§è¡Œçš„è¯¦ç»†æ—¥å¿—
â”‚   â””â”€â”€ scheduler.log                  # è°ƒåº¦å™¨æ—¥å¿—
â”œâ”€â”€ data_archive/
â”‚   â””â”€â”€ version_YYYYMMDD_HHMMSS/     # å†å²ç‰ˆæœ¬å½’æ¡£
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ pipeline_report_YYYYMMDD_HHMMSS.md  # æ‰§è¡ŒæŠ¥å‘Š
â””â”€â”€ scripts/
    â”œâ”€â”€ inference_max_pipeline.py    # ä¸»ç®¡é“è„šæœ¬
    â”œâ”€â”€ scheduler.py                  # è°ƒåº¦å™¨è„šæœ¬
    â””â”€â”€ setup.py                      # å®‰è£…è„šæœ¬
```

## âš™ï¸ é…ç½®è¯´æ˜

### ä¸»é…ç½®æ–‡ä»¶: `inference_max_pipeline/config/pipeline_config.yaml`

#### æ•°æ®æºé…ç½®
```yaml
source:
  base_url: "https://inferencemax.semianalysis.com/"
  timeout: 600
  retry_attempts: 3
  retry_delay: 5
```

#### ç›®æ ‡é…ç½®
```yaml
targets:
  models:
    - "Llama 3.3 70B Instruct"
    - "gpt-oss 120B"
    - "DeepSeek R1 0528"
  sequences:
    - "1K / 1K"
    - "1K / 8K"
    - "8K / 1K"
```

#### è°ƒåº¦é…ç½®
```yaml
scheduling:
  enabled: true
  cron_expression: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹
  timezone: "UTC"
```

#### ç‰ˆæœ¬æ§åˆ¶
```yaml
versioning:
  enabled: true
  max_versions: 30
  compression: true
  date_format: "%Y%m%d_%H%M%S"
```

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬å‘½ä»¤

```bash
# æŸ¥çœ‹å¸®åŠ©
python inference_max_pipeline/scripts/scheduler.py --help

# æ‰§è¡Œä¸€æ¬¡å®Œæ•´ç®¡é“
python inference_max_pipeline/scripts/scheduler.py --once

# ä»¥å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼è¿è¡Œ
python inference_max_pipeline/scripts/scheduler.py --daemon

# æµ‹è¯•è°ƒåº¦é…ç½®
python inference_max_pipeline/scripts/scheduler.py --test

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
python inference_max_pipeline/scripts/scheduler.py --config custom_config.yaml
```

### å•ç‹¬æ‰§è¡Œå„ä¸ªæ­¥éª¤

å¦‚æœéœ€è¦å•ç‹¬æ‰§è¡ŒæŸä¸ªæ­¥éª¤ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œå¯¹åº”çš„è„šæœ¬ï¼š

```bash
# 1. æ•°æ®çˆ¬å–
python comprehensive_scraper.py

# 2. æ•°æ®æ¸…ç†
python clean_json_files.py

# 3. CSVè½¬æ¢
python convert_to_separated_csv.py

# 4. CSVåˆå¹¶
python join_csv_files.py
```

## ğŸ“Š è¾“å‡ºæ–‡ä»¶

### ä¸»è¦è¾“å‡ºæ–‡ä»¶

1. **json_data/inference_max_merged.csv** - æœ€ç»ˆåˆå¹¶çš„æ•°æ®é›†
2. **json_data/inference_max_interactivity.csv** - äº¤äº’å¼æ€§èƒ½æ•°æ®
3. **json_data/inference_max_e2e.csv** - ç«¯åˆ°ç«¯æ€§èƒ½æ•°æ®

### å†å²å½’æ¡£

- **inference_max_pipeline/data_archive/** - å†å²ç‰ˆæœ¬æ•°æ®
- æ¯æ¬¡æ‰§è¡Œéƒ½ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„ç‰ˆæœ¬ç›®å½•
- æ”¯æŒå‹ç¼©å­˜å‚¨ä»¥èŠ‚çœç©ºé—´

### æŠ¥å‘Šå’Œæ—¥å¿—

- **inference_max_pipeline/reports/** - æ‰§è¡ŒæŠ¥å‘Š
- **inference_max_pipeline/logs/** - è¯¦ç»†æ—¥å¿—

## ğŸ” ç›‘æ§å’Œæ•…éšœæ’é™¤

### æŸ¥çœ‹æ‰§è¡ŒçŠ¶æ€

```bash
# æŸ¥çœ‹æœ€æ–°çš„æ‰§è¡Œæ—¥å¿—
ls -la inference_max_pipeline/logs/ | tail -5
tail -f inference_max_pipeline/logs/pipeline_$(date +%Y%m%d)*.log

# æŸ¥çœ‹æ‰§è¡ŒæŠ¥å‘Š
ls -la inference_max_pipeline/reports/ | tail -5
cat inference_max_pipeline/reports/pipeline_report_$(date +%Y%m%d)*.md
```

### å¸¸è§é—®é¢˜

#### 1. ChromeDriver é—®é¢˜
```bash
# æ£€æŸ¥ChromeDriver
chromedriver --version

# é‡æ–°å®‰è£…ChromeDriver
wget -O /tmp/chromedriver.zip https://chromedriver.storage.googleapis.com/LATEST_RELEASE/chromedriver_linux64.zip
cd /tmp && unzip chromedriver.zip && sudo mv chromedriver /usr/local/bin/ && sudo chmod +x /usr/local/bin/chromedriver
```

#### 2. æƒé™é—®é¢˜
```bash
# è®¾ç½®æ‰§è¡Œæƒé™
chmod +x inference_max_pipeline/scripts/*.py
chmod +x json_data/raw_json_files/*.json
```

#### 3. å†…å­˜ä¸è¶³
```bash
# ç›‘æ§å†…å­˜ä½¿ç”¨
free -h

# å¦‚æœå†…å­˜ä¸è¶³ï¼Œå¯ä»¥è€ƒè™‘ï¼š
# 1. å¢åŠ swapç©ºé—´
# 2. è°ƒæ•´Chromeé€‰é¡¹å‡å°‘å†…å­˜ä½¿ç”¨
# 3. ä½¿ç”¨æ›´è½»é‡çº§çš„æµè§ˆå™¨
```

#### 4. ç½‘ç»œé—®é¢˜
```bash
# æµ‹è¯•ç½‘ç»œè¿æ¥
curl -I https://inferencemax.semianalysis.com/

# å¦‚æœç½‘ç»œè¶…æ—¶ï¼Œåœ¨é…ç½®æ–‡ä»¶ä¸­å¢åŠ timeoutå€¼
```

### æ•°æ®è´¨é‡æ£€æŸ¥

```bash
# æ£€æŸ¥æœ€ç»ˆCSVæ–‡ä»¶
wc -l json_data/inference_max_merged.csv
head -5 json_data/inference_max_merged.csv

# æ£€æŸ¥æ•°æ®åˆ†å¸ƒ
cut -d',' -f1 json_data/inference_max_merged.csv | sort | uniq -c
```

## ğŸ“ˆ é«˜çº§é…ç½®

### è‡ªå®šä¹‰è°ƒåº¦

```yaml
scheduling:
  enabled: true
  cron_expression: "0 */6 * * *"  # æ¯6å°æ—¶
  # æˆ–è€…
  cron_expression: "0 0 * * 0"     # æ¯å‘¨æ—¥
```

### é€šçŸ¥é…ç½®

```yaml
notifications:
  webhook:
    enabled: true
    url: "https://hooks.slack.com/services/..."

  email:
    enabled: true
    smtp_server: "smtp.gmail.com"
    smtp_port: 587
    username: "your-email@gmail.com"
    password: "your-app-password"
    recipients: ["admin@example.com"]
```

### æ€§èƒ½è°ƒä¼˜

```yaml
performance:
  max_concurrent_downloads: 3
  request_timeout: 30
  page_load_timeout: 10
```

## ğŸ“‹ ç»´æŠ¤å»ºè®®

### å®šæœŸç»´æŠ¤ä»»åŠ¡

1. **æ¯å‘¨æ£€æŸ¥**
   - æŸ¥çœ‹æ‰§è¡Œæ—¥å¿—
   - éªŒè¯æ•°æ®è´¨é‡
   - æ£€æŸ¥ç£ç›˜ç©ºé—´

2. **æ¯æœˆç»´æŠ¤**
   - æ¸…ç†æ—§ç‰ˆæœ¬ï¼ˆå¦‚æœéœ€è¦ï¼‰
   - æ›´æ–°ä¾èµ–åŒ…
   - å¤‡ä»½é‡è¦æ•°æ®

3. **æ•…éšœå“åº”**
   - ç›‘æ§æ—¥å¿—é”™è¯¯
   - æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
   - éªŒè¯è¾“å‡ºæ–‡ä»¶

### å¤‡ä»½ç­–ç•¥

```bash
# å¤‡ä»½é…ç½®æ–‡ä»¶
tar -czf inference_max_pipeline_backup_$(date +%Y%m%d).tar.gz \
    inference_max_pipeline/config/ \
    inference_max_pipeline/scripts/

# å¤‡ä»½é‡è¦æ•°æ®
tar -czf inference_max_data_backup_$(date +%Y%m%d).tar.gz \
    json_data/inference_max_*.csv \
    inference_max_pipeline/reports/ \
    inference_max_pipeline/logs/
```

## ğŸ› ï¸ æ‰©å±•å’Œå®šåˆ¶

### æ·»åŠ æ–°çš„æ•°æ®å¤„ç†æ­¥éª¤

1. åœ¨ `inference_max_pipeline/scripts/` ä¸­åˆ›å»ºæ–°çš„è„šæœ¬
2. åœ¨ `inference_max_pipeline.py` ä¸­æ·»åŠ æ–°çš„æ­¥éª¤å‡½æ•°
3. æ›´æ–°é…ç½®æ–‡ä»¶ä»¥æ”¯æŒæ–°çš„å‚æ•°

### é›†æˆå…¶ä»–æ•°æ®æº

1. ä¿®æ”¹é…ç½®æ–‡ä»¶æ·»åŠ æ–°çš„æ•°æ®æºé…ç½®
2. åˆ›å»ºå¯¹åº”çš„çˆ¬å–è„šæœ¬
3. åœ¨ä¸»ç®¡é“ä¸­é›†æˆæ–°çš„æ•°æ®æµ

### è‡ªå®šä¹‰æ•°æ®å¤„ç†

1. ä¿®æ”¹ `convert_to_separated_csv.py` æ”¹å˜CSVè½¬æ¢é€»è¾‘
2. ä¿®æ”¹ `join_csv_files.py` æ”¹å˜åˆå¹¶ç­–ç•¥
3. æ·»åŠ æ•°æ®éªŒè¯å’Œæ¸…æ´—è§„åˆ™

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
grep "ERROR" inference_max_pipeline/logs/pipeline_*.log

# æŸ¥çœ‹æ€§èƒ½ç»Ÿè®¡
grep "å®Œæˆ" inference_max_pipeline/logs/pipeline_*.log

# åˆ†ææ‰§è¡Œæ—¶é—´
grep "æ‰§è¡Œæ—¶é•¿" inference_max_pipeline/reports/pipeline_report_*.md
```

### æ€§èƒ½ç›‘æ§

```bash
# ç›‘æ§ç³»ç»Ÿèµ„æº
top -p $(pgrep -f inference_max_pipeline)

# ç›‘æ§ç£ç›˜ä½¿ç”¨
du -sh inference_max_pipeline/
df -h
```

---

*æœ¬æŒ‡å—æ¶µç›–äº† InferenceMAX æ•°æ®ç®¡é“çš„å®Œæ•´ä½¿ç”¨æ–¹æ³•ã€‚å¦‚æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚*